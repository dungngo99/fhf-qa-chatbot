{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da771e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11e09f",
   "metadata": {},
   "source": [
    "## First approach: we use NLTK library to tokenize a list of questions to binary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c2ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ngodylan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ngodylan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b727f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(answer, question):\n",
    "    answers, questions = [], []\n",
    "    \n",
    "    with open(answer, 'r') as file:\n",
    "        answers = file.readlines()\n",
    "        \n",
    "    with open(question, 'r') as file:\n",
    "        questions = file.readlines()\n",
    "        \n",
    "    return answers, questions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d854e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ngodylan/Downloads/Tulane/Fall 2021/CS Capstone/codes\n",
      "Chatbot.ipynb  \u001b[34mFHFCapstone\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2099d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers, questions = read_file(\"FHFCapstone/answers.txt\", \"FHFCapstone/questions.txt\")\n",
    "len(answers), len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e667ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "def find_similarity(questions, user):\n",
    "    ranks = []    \n",
    "    \n",
    "    # tokenize the user's question\n",
    "    tokenized_user = word_tokenize(user)\n",
    "    user_set = {w for w in tokenized_user if not w in sw}\n",
    "    \n",
    "    for idx, question in enumerate(questions):\n",
    "        l1, l2 = [], []\n",
    "        \n",
    "        # tokenize the DB's question\n",
    "        tokenized_question = word_tokenize(question)\n",
    "        question_set = {w for w in tokenized_question if not w in sw}\n",
    "        \n",
    "        rvector = question_set.union(user_set)\n",
    "        for w in rvector:\n",
    "            if w in user_set: l1.append(1)\n",
    "            else: l1.append(0)\n",
    "                \n",
    "            if w in question_set: l2.append(1)\n",
    "            else: l2.append(0)\n",
    "                \n",
    "        c = 0\n",
    "        # cosine formular\n",
    "        for i in range(len(rvector)):\n",
    "            c += l1[i]*l2[i]\n",
    "        cosine = c / ((sum(l1)**0.5*(sum(l2))**0.5))\n",
    "        \n",
    "        # for each question, find its similarity to user's question\n",
    "        ranks.append((idx, cosine))\n",
    "        \n",
    "    # sort the ranks\n",
    "    ranks.sort(key=lambda y: y[1], reverse=True)\n",
    "    return ranks\n",
    "\n",
    "def answer(ranks, answers):\n",
    "    f_idx, s_idx = ranks[0][0], ranks[1][0]\n",
    "    \n",
    "    print(\"The first answer is\", answers[f_idx])\n",
    "    print(\"The second answer is\", answers[s_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c244028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first answer is IEP is an individualized Education Program that provides a written plan designed to meet the unique needs of the child with an exceptionality.\n",
      "\n",
      "The second answer is At any IEP Team meeting, the following participants shall be in attendance: an officially designated representative of the Local Education Agency (LEA), the student\\'s regular education and special education teachers, the student\\'s parents, and a person knowledgeable about the student\\'s evaluation procedures and results. The student, as well as other individuals the parents and/or LEA may deem necessary, should be given the opportunity to attend. Documentation of attendance is required.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranks = find_similarity(questions, \"Can you tell me what an IEP is\")\n",
    "answer(ranks, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedd7a3",
   "metadata": {},
   "source": [
    "## Second approach: instead of using NLTK, we use TFIDF from scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7244166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF stands for frequency-inverse document frequency\n",
    "# try to find the most frequent and significant words\n",
    "\n",
    "# tf-idf = term_frequency * inverse_document_frequency\n",
    "# inverse_document_frequency = log(total number of documents / number of documents with term) + 1\n",
    "# Ex: a word that appears a lot in 1-2 pages is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6120a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bbc9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./FHFCapstone/questions.txt', './FHFCapstone/answers.txt'],\n",
       " ['questions', 'answers'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = \"./FHFCapstone\"\n",
    "text_files = glob.glob(f\"{directory_path}/*.txt\")\n",
    "titles = [Path(text_file).stem for text_file in text_files]\n",
    "text_files, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "173952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input='filename', stop_words=\"english\")\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1dfe9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1508</th>\n",
       "      <th>1706</th>\n",
       "      <th>21</th>\n",
       "      <th>30</th>\n",
       "      <th>60</th>\n",
       "      <th>ability</th>\n",
       "      <th>academic</th>\n",
       "      <th>achieve</th>\n",
       "      <th>achievement</th>\n",
       "      <th>acquired</th>\n",
       "      <th>...</th>\n",
       "      <th>using</th>\n",
       "      <th>various</th>\n",
       "      <th>visual</th>\n",
       "      <th>vital</th>\n",
       "      <th>ward</th>\n",
       "      <th>way</th>\n",
       "      <th>welfare</th>\n",
       "      <th>work</th>\n",
       "      <th>written</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>questions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers</th>\n",
       "      <td>0.070641</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.047094</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.047094</td>\n",
       "      <td>0.070641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1508      1706        21        30        60   ability  \\\n",
       "questions  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "answers    0.070641  0.023547  0.023547  0.023547  0.023547  0.023547   \n",
       "\n",
       "           academic   achieve  achievement  acquired  ...     using   various  \\\n",
       "questions  0.000000  0.000000     0.000000  0.000000  ...  0.000000  0.000000   \n",
       "answers    0.047094  0.023547     0.023547  0.023547  ...  0.023547  0.023547   \n",
       "\n",
       "             visual     vital      ward       way   welfare      work  \\\n",
       "questions  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "answers    0.023547  0.023547  0.023547  0.023547  0.023547  0.023547   \n",
       "\n",
       "            written       yes  \n",
       "questions  0.000000  0.000000  \n",
       "answers    0.047094  0.070641  \n",
       "\n",
       "[2 rows x 351 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=titles, columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa1387c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>doc_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>child</th>\n",
       "      <td>0.364101</td>\n",
       "      <td>0.284815</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.364101</td>\n",
       "      <td>0.167538</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iep</th>\n",
       "      <td>0.364101</td>\n",
       "      <td>0.150784</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluation</th>\n",
       "      <td>0.218460</td>\n",
       "      <td>0.134031</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>0.218460</td>\n",
       "      <td>0.083769</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vital</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ward</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welfare</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            questions   answers  doc_freq\n",
       "child        0.364101  0.284815       2.0\n",
       "school       0.364101  0.167538       2.0\n",
       "iep          0.364101  0.150784       2.0\n",
       "evaluation   0.218460  0.134031       2.0\n",
       "team         0.218460  0.083769       2.0\n",
       "...               ...       ...       ...\n",
       "vital        0.000000  0.023547       1.0\n",
       "ward         0.000000  0.023547       1.0\n",
       "way          0.000000  0.023547       1.0\n",
       "welfare      0.000000  0.023547       1.0\n",
       "work         0.000000  0.023547       1.0\n",
       "\n",
       "[351 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.loc['doc_freq'] = (tfidf_df > 0).sum()\n",
    "df = tfidf_df.T.sort_values(by=['questions', 'answers'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558de13",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Although TFIDF in this case is a good approach, it may not help us solve the problem of ranking questions with user's question in term of similarity. TFIDF will output the significance of a term based on all question/answer pairs. However, these pairs are independent and unrelated. Furthermore, a user's questiion and DB's question both have significant words but they are unrelated, so their similarity is incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a0be9e",
   "metadata": {},
   "source": [
    "### task\n",
    "1. Form a list of 21 pairs (answer+question)\n",
    "2. Fit and transform TF-IDF vectorizer for these 21 pairs, then turn each pair (string) into a vector.\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
